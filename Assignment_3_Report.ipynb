{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-3-Report.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prinakk/A3_ML_UTS2019/blob/master/Assignment_3_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvpYfQiO7-gN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# GitHub Link\n",
        "\n",
        "https://github.com/prinakk/A3_ML_UTS2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBa3G2QR9Lw5",
        "colab_type": "text"
      },
      "source": [
        "# Video Pitch Link\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTxSkf9b8CkY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Automated Sign Language Translator\n",
        "## Prina Kamakotti\n",
        "## 13171780"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVxhQl4X8zLB",
        "colab_type": "text"
      },
      "source": [
        "# AIM\n",
        "The main objective of this project is to create an automated sign language interpreter in the hopes of promoting communication between people with hearing and speech disability and the world of hearing. To facilitate automated translation, we use Machine learning models. Machine Learning is an application of artificial intelligence which is used to analyse data and apply the results in other situations automatically. Machine Learning enables computers to learn and grow from the data provided, which mimics a human beings ability to grow from past experiences. The main goals of this project are as follow:\n",
        "\n",
        "1.   Image processing to recognise hand gestures.\n",
        "2.   Select appropriate machine learning model and train the model with various sign languages.\n",
        "3.   Validate and deploy the project.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdbw9zog9DZN",
        "colab_type": "text"
      },
      "source": [
        "# BACKGROUND\n",
        "\n",
        "Translating is a tough endeavour even amongst spoken languages, let alone translation of sign language. Sign language is the main form of communication of people with hearing or speech disabilities. According to the World Health Organization, any type of hearing or speech impairment affects about 5 per cent of the world's population. This is a vast number of people affected, nearly 450 million human beings. So sign language to them is the choice of communication. Like every spoken language, which has variations and dialects according to the location of origin, the world currently has more than a hundred different sign languages. To people with no hearing or speech disabilities, learning sign language is usually a neglected cause, hence communicating with people who have such disabilities is extremely arduous. \n",
        "\n",
        "\n",
        "Machine translation of sign language has been available from 1977, albeit with limited capabilities. Sign Language translation began through the use of hand gesture recognition equipment such as gloves with motion sensors etc. and with the current digital age development, cameras and digital recordings replaced the old hand glove hardware, making it much easier to interpret sign language.  As seen in the objectives, the first hurdle in the translation process is to recognise the hand gestures, and a literature review of this problem shows that there have been several methods to address this issue. Cohen et al. (2003) proposed an ensemble method which used Hidden Markov Models, which is a statistical machine learning method along with traditional machine learning models. Boulay et al. (2003) developed a method to recognise human postures in video sequences with the help of a three-dimensional human model and to compare the sequence with it. From the literature review, It can be assumed that the many proposed methods can all be used to identify the hand gesture, and it is advised to choose the most suitable method for the data."
      ]
    }
  ]
}